import cv2
import numpy as np
from PIL import Image
from pathlib import Path


def enhance_image_for_ocr(image_path: Path, save_debug: bool = False) -> np.ndarray:
    """
    Pipeline complet de preprocessing pour cartes m√©t√©o :
    - Upscaling pour petit texte
    - Isolation du texte noir
    - Enhancement contraste
    - Binarisation
    - Nettoyage bruit
    
    Args:
        image_path: Chemin vers l'image √† traiter
        save_debug: Si True, sauvegarde les √©tapes interm√©diaires
    
    Returns:
        Image preprocess√©e (numpy array) ou None si erreur
    """
    
    # Convertir Path en string pour compatibilit√© OpenCV Windows
    img_path_str = str(image_path)
    
    # Charger image
    img = cv2.imread(img_path_str)
    
    if img is None:
        print(f"‚ùå Impossible de charger l'image: {image_path.name}")
        print(f"   Chemin: {img_path_str}")
        print(f"   Existe? {image_path.exists()}")
        return None
    
    print(f"‚úÖ Image charg√©e: {img.shape[1]}x{img.shape[0]} pixels")
    
    # 1. Upscale x3 (crucial pour texte petit sur cartes)
    height, width = img.shape[:2]
    img_upscaled = cv2.resize(
        img, 
        (width * 3, height * 3), 
        interpolation=cv2.INTER_CUBIC
    )
    
    # 2. Conversion HSV pour isoler texte noir
    hsv = cv2.cvtColor(img_upscaled, cv2.COLOR_BGR2HSV)
    
    # 3. Masque pour isoler texte noir (temp√©ratures en noir sur cartes)
    # HSV: Hue, Saturation, Value
    # Texte noir = faible Value, toute Saturation
    lower_black = np.array([0, 0, 0])
    upper_black = np.array([180, 255, 100])  # V < 100 = sombre
    mask = cv2.inRange(hsv, lower_black, upper_black)
    
    # 4. Inverser masque (texte devient blanc sur fond noir)
    mask_inv = cv2.bitwise_not(mask)
    
    # 5. Conversion grayscale classique
    gray = cv2.cvtColor(img_upscaled, cv2.COLOR_BGR2GRAY)
    
    # 6. Appliquer masque pour isoler texte
    text_only = cv2.bitwise_and(gray, gray, mask=mask_inv)
    
    # 7. Augmenter contraste fortement avec CLAHE
    clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(text_only)
    
    # 8. R√©duire bruit avant binarisation
    denoised = cv2.fastNlMeansDenoising(
        enhanced, 
        None, 
        h=10, 
        templateWindowSize=7, 
        searchWindowSize=21
    )
    
    # 9. Binarisation avec seuil adaptatif (meilleur pour fond complexe)
    binary = cv2.adaptiveThreshold(
        denoised,
        255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY,
        blockSize=15,
        C=4
    )
    
    # 10. Morphologie : Fermer petits trous dans les lettres
    kernel = np.ones((2, 2), np.uint8)
    morph = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
    
    # 11. Dilater l√©g√®rement pour √©paissir le texte
    dilated = cv2.dilate(morph, kernel, iterations=1)
    
    # 12. Nettoyage final
    final = cv2.medianBlur(dilated, 3)
    
    # 13. V√©rifier orientation (texte doit √™tre noir sur blanc)
    white_pixels = np.sum(final == 255)
    black_pixels = np.sum(final == 0)
    
    if white_pixels < black_pixels:
        # Inverser si n√©cessaire
        final = cv2.bitwise_not(final)
        print("üîÑ Image invers√©e (texte noir sur fond blanc)")
    
    # Sauvegarder images debug
    if save_debug:
        debug_dir = image_path.parent / "debug"
        debug_dir.mkdir(exist_ok=True)
        
        print(f"üíæ Sauvegarde images debug dans: {debug_dir}")
        
        # Sauvegarder chaque √©tape (utiliser str() pour Windows)
        cv2.imwrite(str(debug_dir / f"{image_path.stem}_1_upscaled.png"), img_upscaled)
        cv2.imwrite(str(debug_dir / f"{image_path.stem}_2_mask.png"), mask)
        cv2.imwrite(str(debug_dir / f"{image_path.stem}_3_text_only.png"), text_only)
        cv2.imwrite(str(debug_dir / f"{image_path.stem}_4_enhanced.png"), enhanced)
        cv2.imwrite(str(debug_dir / f"{image_path.stem}_5_denoised.png"), denoised)
        cv2.imwrite(str(debug_dir / f"{image_path.stem}_6_binary.png"), binary)
        cv2.imwrite(str(debug_dir / f"{image_path.stem}_7_morph.png"), morph)
        cv2.imwrite(str(debug_dir / f"{image_path.stem}_8_FINAL.png"), final)
        
        print(f"‚úÖ 8 images debug sauvegard√©es")
    
    return final


def extract_text_regions(image_path: Path) -> list:
    """
    D√©tecte et extrait les r√©gions contenant du texte
    (Alternative avanc√©e pour d√©coupe intelligente)
    
    Args:
        image_path: Chemin vers l'image
    
    Returns:
        Liste de dictionnaires avec images de r√©gions et coordonn√©es
    """
    
    img_path_str = str(image_path)
    img = cv2.imread(img_path_str)
    
    if img is None:
        return []
    
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # D√©tection de contours
    _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)
    
    # Trouver contours
    contours, _ = cv2.findContours(
        binary, 
        cv2.RETR_EXTERNAL, 
        cv2.CHAIN_APPROX_SIMPLE
    )
    
    # Filtrer contours de taille texte
    text_regions = []
    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        
        # Filtrer par taille (ajuster selon PDFs)
        if 10 < w < 300 and 10 < h < 100:
            # Extraire r√©gion
            region = img[y:y+h, x:x+w]
            text_regions.append({
                'image': region,
                'bbox': (x, y, w, h)
            })
    
    return text_regions


def apply_sharpening(image: np.ndarray, strength: int = 1) -> np.ndarray:
    """
    Applique un filtre de nettet√© √† l'image
    
    Args:
        image: Image numpy array
        strength: Intensit√© (1-3)
    
    Returns:
        Image avec nettet√© augment√©e
    """
    
    # Kernel de nettet√©
    kernel = np.array([
        [-1, -1, -1],
        [-1, 9, -1],
        [-1, -1, -1]
    ])
    
    sharpened = image.copy()
    for _ in range(strength):
        sharpened = cv2.filter2D(sharpened, -1, kernel)
    
    return sharpened


def remove_background_color(image_path: Path, target_color_bgr: tuple = (255, 200, 200)) -> np.ndarray:
    """
    Enl√®ve une couleur d'arri√®re-plan sp√©cifique (ex: fond bleu des cartes)
    
    Args:
        image_path: Chemin vers l'image
        target_color_bgr: Couleur BGR √† enlever
    
    Returns:
        Image avec fond blanc
    """
    
    img = cv2.imread(str(image_path))
    
    if img is None:
        return None
    
    # Convertir en HSV pour mieux cibler couleur
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    
    # D√©finir range de couleur √† enlever (ex: bleu)
    # Ajuster selon la couleur de vos cartes
    lower = np.array([100, 50, 50])   # Bleu fonc√©
    upper = np.array([130, 255, 255]) # Bleu clair
    
    # Cr√©er masque
    mask = cv2.inRange(hsv, lower, upper)
    
    # Remplacer par blanc
    img[mask > 0] = [255, 255, 255]
    
    return img


def auto_rotate_text(image: np.ndarray) -> np.ndarray:
    """
    D√©tecte et corrige l'orientation du texte automatiquement
    
    Args:
        image: Image numpy array
    
    Returns:
        Image r√©orient√©e
    """
    
    # Utiliser pytesseract pour d√©tecter orientation
    try:
        import pytesseract
        from PIL import Image as PILImage
        
        # Convertir numpy -> PIL
        pil_img = PILImage.fromarray(image)
        
        # D√©tecter orientation
        osd = pytesseract.image_to_osd(pil_img)
        
        # Extraire angle de rotation
        angle = int(osd.split('\n')[2].split(':')[1].strip())
        
        if angle != 0:
            print(f"üîÑ Rotation d√©tect√©e: {angle}¬∞")
            
            # Cr√©er matrice de rotation
            h, w = image.shape[:2]
            center = (w // 2, h // 2)
            M = cv2.getRotationMatrix2D(center, angle, 1.0)
            
            # Appliquer rotation
            rotated = cv2.warpAffine(image, M, (w, h), 
                                     flags=cv2.INTER_CUBIC,
                                     borderMode=cv2.BORDER_REPLICATE)
            
            return rotated
    
    except Exception as e:
        print(f"‚ö†Ô∏è Auto-rotation √©chou√©e: {e}")
    
    return image
